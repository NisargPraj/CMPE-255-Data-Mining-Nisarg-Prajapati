{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f83f8b",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "This notebook uses the Titanic dataset to predict survival based on various passenger features. The workflow follows CRISP-DM methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5586a7",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load the Titanic dataset\n",
    "file_path = '/path_to_your_data/train.csv'\n",
    "titanic_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "titanic_data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5b690",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "In this step, we handle missing values, encode categorical variables, and scale numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
    "titanic_data.drop('Cabin', axis=1, inplace=True)\n",
    "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
    "titanic_data = pd.get_dummies(titanic_data, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Select relevant features\n",
    "features_to_keep = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']\n",
    "titanic_prepared = titanic_data[features_to_keep]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "titanic_prepared[['Age', 'SibSp', 'Parch', 'Fare']] = scaler.fit_transform(titanic_prepared[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "titanic_prepared.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab2244",
   "metadata": {},
   "source": [
    "## Step 3: Splitting Data and Training Models\n",
    "Now we split the data into training and testing sets and train a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the target variable and features\n",
    "X = titanic_prepared\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db079b5",
   "metadata": {},
   "source": [
    "## Step 4: Saving the Model\n",
    "Finally, we save the trained Random Forest model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "model_filename = 'final_random_forest_model.pkl'\n",
    "joblib.dump(rf_clf, model_filename)\n",
    "\n",
    "# To download the model, you can use the following code in a Colab cell:\n",
    "# from google.colab import files\n",
    "# files.download('final_random_forest_model.pkl')\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}